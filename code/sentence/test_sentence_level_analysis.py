# sentence_level_analysis.py

import pandas as pd
import numpy as np
import os
from scipy.stats import spearmanr, norm
from statsmodels.tsa.stattools import acf
import matplotlib.pyplot as plt
import warnings

def load_data(file_path):
    """
    Load the data from the CSV file into a pandas DataFrame.

    Parameters:
    - file_path (str): Path to the CSV file.

    Returns:
    - pd.DataFrame: Loaded DataFrame.
    """
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"The file at {file_path} does not exist.")
    df = pd.read_csv(file_path, encoding='utf-8')
    return df

def preprocess_data(df):
    """
    Preprocess the data:
    - Ensure the number of sentences matches the number of labels.
    - Exclude rows where they don't match.
    - Recode label '2' as '0'.
    - Process labels to create binary sequences.

    Parameters:
    - df (pd.DataFrame): Original DataFrame.

    Returns:
    - pd.DataFrame: Preprocessed DataFrame.
    """
    # Function to count the number of sentences in the response
    def count_sentences(response):
        if pd.isnull(response):
            return 0
        sentences = response.strip().split('\n')
        # Remove empty strings and ensure sentences are numbered
        sentences = [s for s in sentences if s.strip() and s.strip()[0].isdigit()]
        return len(sentences)

    # Function to count the number of labels in labeled_response
    def count_labels(label_sequence):
        if pd.isnull(label_sequence):
            return 0
        labels = [label.strip() for label in str(label_sequence).split(',')]
        labels = [label for label in labels if label.isdigit()]
        return len(labels)

    # Apply counting functions
    df['sentence_count'] = df['response'].apply(count_sentences)
    df['label_count'] = df['labeled_response'].apply(count_labels)

    # Filter rows where sentence_count matches label_count
    df_filtered = df[df['sentence_count'] == df['label_count']].copy()
    if df_filtered.empty:
        warnings.warn("No rows with matching sentence and label counts found.")

    # Recode label '2' as '0' and process labels into lists
    df_filtered['labels_processed'] = df_filtered['labeled_response'].apply(
        lambda x: [0 if label.strip() == '2' else int(label.strip()) 
                  for label in str(x).split(',') if label.strip().isdigit()]
    )

    return df_filtered

def calculate_proportions(df):
    """
    Calculate the proportion of sentences labelled as hallucinatory (label == 1).

    Parameters:
    - df (pd.DataFrame): Preprocessed DataFrame.

    Returns:
    - pd.DataFrame: DataFrame with an additional 'proportion_hallucinatory' column.
    """
    # Function to calculate proportion for each row
    def proportion_hallucinatory(labels):
        total = len(labels)
        if total == 0:
            return np.nan
        hallucinatory = sum(1 for label in labels if label == 1)
        return hallucinatory / total

    df['proportion_hallucinatory'] = df['labels_processed'].apply(proportion_hallucinatory)
    return df

def test_h1a(df):
    """
    Test H1a: The proportion of sentences labelled as hallucinatory is greater in responses generated with a higher temperature level.

    Parameters:
    - df (pd.DataFrame): DataFrame with 'proportion_hallucinatory'.

    Returns:
    - pd.DataFrame: H1a results with Spearman correlation coefficients and p-values.
    """
    labelling_models = df['labelling model'].unique()
    h1a_results = []

    print("Performing H1a Analysis...\n")
    for lab_model in labelling_models:
        df_lab = df[df['labelling model'] == lab_model]
        # Group by temperature and calculate mean proportion
        temp_group = df_lab.groupby('input_temperature')['proportion_hallucinatory'].mean().reset_index()
        # Remove NaN values
        temp_group = temp_group.dropna(subset=['proportion_hallucinatory'])
        if len(temp_group) < 2:
            warnings.warn(f"Not enough data to compute Spearman correlation for labelling model '{lab_model}'.")
            continue
        corr, p_value = spearmanr(temp_group['input_temperature'], temp_group['proportion_hallucinatory'])
        h1a_results.append({
            'labelling_model': lab_model,
            'spearman_correlation': corr,
            'p_value': p_value
        })
        print(f"H1a - Labelling Model: {lab_model}")
        print(f"Spearman correlation: {corr:.4f}, p-value: {p_value:.4f}\n")

    h1a_df = pd.DataFrame(h1a_results)
    return h1a_df

def test_h1b(df):
    """
    Test H1b: The proportion of sentences labelled as hallucinatory is greater in responses generated by smaller LLMs.

    Parameters:
    - df (pd.DataFrame): DataFrame with 'proportion_hallucinatory'.

    Returns:
    - pd.DataFrame: H1b results with Spearman correlation coefficients and p-values.
    """
    labelling_models = df['labelling model'].unique()
    # Map generating models to sizes
    model_sizes = {
        'qwen2(0.5b)': 0.5,
        'qwen2': 6,
        'llama3.1': 8,
        'gemma2': 9,
        'mistral-nemo': 12
    }
    df['model_size'] = df['generating model'].map(model_sizes)
    h1b_results = []

    print("Performing H1b Analysis...\n")
    for lab_model in labelling_models:
        df_lab = df[df['labelling model'] == lab_model]
        # Group by model size and calculate mean proportion
        size_group = df_lab.groupby('model_size')['proportion_hallucinatory'].mean().reset_index()
        # Remove NaN values
        size_group = size_group.dropna(subset=['proportion_hallucinatory', 'model_size'])
        if len(size_group) < 2:
            warnings.warn(f"Not enough data to compute Spearman correlation for labelling model '{lab_model}'.")
            continue
        corr, p_value = spearmanr(size_group['model_size'], size_group['proportion_hallucinatory'])
        h1b_results.append({
            'labelling_model': lab_model,
            'spearman_correlation': corr,
            'p_value': p_value
        })
        print(f"H1b - Labelling Model: {lab_model}")
        print(f"Spearman correlation: {corr:.4f}, p-value: {p_value:.4f}\n")

    h1b_df = pd.DataFrame(h1b_results)
    return h1b_df

def test_h2a(df):
    """
    Test H2a: The autocorrelation coefficient at lag 1 is greater than 0.

    Parameters:
    - df (pd.DataFrame): Preprocessed DataFrame.

    Returns:
    - pd.DataFrame: H2a results with autocorrelation at lag 1 and p-values.
    """
    labelling_models = df['labelling model'].unique()
    h2a_results = []

    print("Performing H2a Analysis...\n")
    for lab_model in labelling_models:
        df_lab = df[df['labelling model'] == lab_model]
        for gen_model in df_lab['generating model'].unique():
            df_gen = df_lab[df_lab['generating model'] == gen_model]
            for temp in df_gen['input_temperature'].unique():
                df_temp = df_gen[df_gen['input_temperature'] == temp]
                # Combine all sequences
                sequences = df_temp['labels_processed'].tolist()
                # Flatten the sequences
                combined_sequence = [label for seq in sequences for label in seq]
                if len(combined_sequence) < 2:
                    autocorr_lag1 = np.nan
                    p_value = np.nan
                else:
                    autocorr = acf(combined_sequence, nlags=1, fft=False, missing='conservative')
                    autocorr_lag1 = autocorr[1]  # Lag 1 autocorrelation
                    # Compute p-value for autocorr_lag1 > 0 (one-tailed)
                    N = len(combined_sequence)
                    se = 1 / np.sqrt(N)
                    z = autocorr_lag1 / se
                    p_value = 1 - norm.cdf(z)  # One-tailed test
                h2a_results.append({
                    'labelling_model': lab_model,
                    'generating_model': gen_model,
                    'temperature': temp,
                    'autocorr_lag1': autocorr_lag1,
                    'p_value': p_value
                })

    h2a_df = pd.DataFrame(h2a_results)
    print("\nH2a Results:")
    print(h2a_df)
    return h2a_df

def test_h2b(df):
    """
    Test H2b: Autocorrelation coefficients at lags 2, 3, ... are greater than 0, smaller than the coefficient at lag 1, and decreasing as the lag increases.

    Parameters:
    - df (pd.DataFrame): Preprocessed DataFrame.

    Returns:
    - pd.DataFrame: H2b results with Spearman correlation coefficients and p-values.
    """
    labelling_models = df['labelling model'].unique()
    h2b_results = []

    print("Performing H2b Analysis...\n")
    for lab_model in labelling_models:
        df_lab = df[df['labelling model'] == lab_model]
        for gen_model in df_lab['generating model'].unique():
            df_gen = df_lab[df_lab['generating model'] == gen_model]
            for temp in df_gen['input_temperature'].unique():
                df_temp = df_gen[df_gen['input_temperature'] == temp]
                # Combine all sequences
                sequences = df_temp['labels_processed'].tolist()
                # Flatten the sequences
                combined_sequence = [label for seq in sequences for label in seq]
                if len(combined_sequence) < 3:
                    spearman_corr = np.nan
                    p_value = np.nan
                else:
                    autocorr = acf(combined_sequence, nlags=10, fft=False, missing='conservative')
                    autocorr_lags = autocorr[1:]  # Exclude lag 0
                    lags = np.arange(1, len(autocorr_lags)+1)
                    # Test if autocorrelation decreases with lag
                    corr, p_value = spearmanr(lags, autocorr_lags)
                h2b_results.append({
                    'labelling_model': lab_model,
                    'generating_model': gen_model,
                    'temperature': temp,
                    'spearman_correlation': corr,
                    'p_value': p_value
                })

    h2b_df = pd.DataFrame(h2b_results)
    print("\nH2b Results:")
    print(h2b_df)
    return h2b_df

def plot_autocorrelation(df, max_lag=10, save_path_panel1='Autocorrelation_Gemma2.png', save_path_panel2='Autocorrelation_Llama3.1.png'):
    """
    Plot the autocorrelation results in two panels:
    - One panel per labelling model (gemma2 and llama3.1).
    - Each panel contains 5 graphs, one per generating model.
    - Each graph contains 5 lines, one per temperature level.
    - Consistent colors for temperature levels and same y-axis scale.

    Parameters:
    - df (pd.DataFrame): Preprocessed DataFrame with 'labels_processed'.
    - max_lag (int): Maximum lag for autocorrelation.
    - save_path_panel1 (str): File path to save the first panel (Gemma2).
    - save_path_panel2 (str): File path to save the second panel (Llama3.1).
    """
    labelling_models = df['labelling model'].unique()
    generating_models = ['gemma2', 'llama3.1', 'qwen2', 'qwen2(0.5b)', 'mistral-nemo']
    temperatures = [0, 0.75, 1, 1.25, 2]
    temperature_colors = {
        0: 'blue',
        0.75: 'green',
        1: 'red',
        1.25: 'purple',
        2: 'orange'
    }

    # Define y-axis limits for consistency
    y_min = -0.1
    y_max = 1.0  # Adjust based on expected autocorrelation range

    for lab_model in labelling_models:
        fig, axes = plt.subplots(1, len(generating_models), figsize=(25, 5), sharey=True)
        fig.suptitle(f'Autocorrelation of Hallucinatory Sentences by Temperature for {lab_model}', fontsize=16)

        for idx, gen_model in enumerate(generating_models):
            ax = axes[idx]
            for temp in temperatures:
                df_subset = df[
                    (df['labelling model'] == lab_model) &
                    (df['generating model'] == gen_model) &
                    (df['input_temperature'] == temp)
                ]
                sequences = df_subset['labels_processed'].tolist()
                combined_sequence = [label for seq in sequences for label in seq]
                if len(combined_sequence) < 2:
                    autocorr = [np.nan] * max_lag
                else:
                    autocorr_full = acf(combined_sequence, nlags=max_lag, fft=False, missing='conservative')
                    autocorr = autocorr_full[1:max_lag+1]  # Exclude lag 0
                ax.plot(range(1, max_lag+1), autocorr, marker='o', label=f'Temp: {temp}', color=temperature_colors.get(temp, 'black'))
            ax.set_title(f'Generating Model: {gen_model}', fontsize=14)
            ax.set_ylim(y_min, y_max)
            ax.set_xlabel('Lag', fontsize=12)
            ax.set_xticks(range(1, max_lag+1))
            if idx == 0:
                ax.set_ylabel('Autocorrelation', fontsize=12)
            ax.legend(fontsize=10)
            ax.grid(False)  # Remove grid lines

        plt.tight_layout(rect=[0, 0.03, 1, 0.95])
        if lab_model.lower() == 'gemma2':
            fig.savefig(save_path_panel1, dpi=300)
        elif lab_model.lower() == 'llama3.1':
            fig.savefig(save_path_panel2, dpi=300)
        plt.show()

def main():
    # Define the path to the CSV file
    file_path = '/Users/lucmacbookpro-profile/Desktop/summer research/URSS 2024/data_results/sentence/big_data_frame.csv'

    # Load the data
    print("Loading data...")
    df = load_data(file_path)
    print("Data loaded successfully.\n")

    # Preprocess the data
    print("Preprocessing data...")
    df = preprocess_data(df)
    print(f"Data preprocessed. {len(df)} rows retained.\n")

    # Calculate proportions
    print("Calculating proportions of hallucinatory sentences...")
    df = calculate_proportions(df)
    print("Proportions calculated.\n")

    # Test H1a
    h1a_results = test_h1a(df)
    h1a_output_path = 'H1a_results.csv'
    h1a_results.to_csv(h1a_output_path, index=False)
    print(f"H1a results saved to '{h1a_output_path}'.\n")

    # Test H1b
    h1b_results = test_h1b(df)
    h1b_output_path = 'H1b_results.csv'
    h1b_results.to_csv(h1b_output_path, index=False)
    print(f"H1b results saved to '{h1b_output_path}'.\n")

    # Test H2a
    h2a_results = test_h2a(df)
    h2a_output_path = 'H2a_results.csv'
    h2a_results.to_csv(h2a_output_path, index=False)
    print(f"H2a results saved to '{h2a_output_path}'.\n")

    # Test H2b
    h2b_results = test_h2b(df)
    h2b_output_path = 'H2b_results.csv'
    h2b_results.to_csv(h2b_output_path, index=False)
    print(f"H2b results saved to '{h2b_output_path}'.\n")

    # Plot Autocorrelation
    print("Plotting autocorrelation graphs...")
    plot_autocorrelation(df)
    print("Autocorrelation plots have been saved and displayed.\n")

    print("All analyses completed successfully.")

if __name__ == '__main__':
    main() 